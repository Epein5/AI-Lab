{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class PlantVillageCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlantVillageCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(16, 8, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(8 * 16 * 16, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool3(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 8 * 16 * 16)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.CenterCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_dataset = ImageFolder('../Datasets/train', transform=data_transforms['train'])\n",
    "val_dataset = ImageFolder('../Datasets/val', transform=data_transforms['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PlantVillageCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 157/157 [01:13<00:00,  2.15it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:03<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2]\n",
      "Training Loss: 1.8428\n",
      "Validation Loss: 1.3756\n",
      "Validation Accuracy: 0.5600\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 157/157 [00:28<00:00,  5.59it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2]\n",
      "Training Loss: 1.3435\n",
      "Validation Loss: 1.0020\n",
      "Validation Accuracy: 0.6680\n",
      "--------------------------------------------------\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # Move data to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation - now done every epoch instead of every 100 epochs\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Validating'):\n",
    "            # Move data to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Training Loss: {running_loss/len(train_loader):.4f}')\n",
    "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print('-' * 50)\n",
    "\n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping a copy of the original weights (cloning them) so later we can prove that a fine-tuning with LoRA doesn't alter the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = {}\n",
    "for name, param in model.named_parameters():\n",
    "    original_weights[name] = param.clone().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The the performance of the pretrained network. As we can see, the network performs poorly on the digit 9. Let's fine-tune it on the digit 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:02<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.668\n",
      "Wrong predictions for class 0: 29\n",
      "Class 0 Accuracy: 0.71\n",
      "Wrong predictions for class 1: 43\n",
      "Class 1 Accuracy: 0.57\n",
      "Wrong predictions for class 2: 27\n",
      "Class 2 Accuracy: 0.73\n",
      "Wrong predictions for class 3: 52\n",
      "Class 3 Accuracy: 0.48\n",
      "Wrong predictions for class 4: 34\n",
      "Class 4 Accuracy: 0.66\n",
      "Wrong predictions for class 5: 29\n",
      "Class 5 Accuracy: 0.71\n",
      "Wrong predictions for class 6: 62\n",
      "Class 6 Accuracy: 0.38\n",
      "Wrong predictions for class 7: 13\n",
      "Class 7 Accuracy: 0.87\n",
      "Wrong predictions for class 8: 23\n",
      "Class 8 Accuracy: 0.77\n",
      "Wrong predictions for class 9: 20\n",
      "Class 9 Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # First, make sure model is on the correct device\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_counts = [0 for i in range(10)]  # Adjust number based on your classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            # Move both inputs and labels to the same device as model\n",
    "            x = x.to(device)  # Should be shape [batch_size, 3, 256, 256]\n",
    "            y = y.to(device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            \n",
    "            for idx, output in enumerate(outputs):\n",
    "                predicted = torch.argmax(output)\n",
    "                if predicted == y[idx]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    wrong_counts[y[idx].item()] += 1\n",
    "                total += 1\n",
    "\n",
    "    accuracy = round(correct/total, 3)\n",
    "    print(f'Overall Accuracy: {accuracy}')\n",
    "    \n",
    "    # Print wrong predictions for each class\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'Wrong predictions for class {i}: {wrong_counts[i]}')\n",
    "        # Calculate per-class accuracy\n",
    "        class_total = sum(1 for _, label in val_loader.dataset if label == i)\n",
    "        class_accuracy = round((class_total - wrong_counts[i]) / class_total, 3)\n",
    "        print(f'Class {i} Accuracy: {class_accuracy}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how many parameters are in the original network, before introducing the LoRA matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the total parameters counter\n",
    "total_parameters_original = 0\n",
    "\n",
    "# Iterate over all layers in the model\n",
    "for index, layer in enumerate(model.children()):\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        total_parameters_original += layer.weight.nelement()\n",
    "        if layer.bias is not None:\n",
    "            total_parameters_original += layer.bias.nelement()\n",
    "        print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape if layer.bias is not None else \"N/A\"}')\n",
    "\n",
    "print(f'Total number of parameters: {total_parameters_original:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model as sequential_model.pth\n"
     ]
    }
   ],
   "source": [
    "# # Save the trained modeln \n",
    "# torch.save(model.state_dict(), 'sequential_model.pth')\n",
    "# print('Saved trained model as sequential_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratchvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
